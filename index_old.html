<!doctype html>
<html lang="en">
<!--<script>  
        window.onload = function() {  
        if (window == window.parent) {  
            document.body.innerHTML = '';  
        }  
    };  
</script>-->
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <meta name="theme-color" content="#000000" />
  <link rel="stylesheet" href="Open-Sans.css">
  <link rel="stylesheet" href="index.css">
  <title></title>
  <script defer="defer" src="./static/js/main.cb41f6a5.js"></script>
  <link href="./static/css/main.4017e162.css" rel="stylesheet">
</head>

<body>
  <div id="root" class="column-flex">
    <div id="title-flex" class="column-flex">
      <h1 id="title">VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image</h1>
      <span>
        <a target="_blank" href="" onclick="return false;">Sicheng&nbsp;Xu</a><sup>*</sup>,
        <a target="_blank" href="" onclick="return false;">Guojun&nbsp;Chen</a><sup>*</sup>,
        <a target="_blank" href="http://jlyang.org/">Jiaolong&nbsp;Yang</a><sup>‡</sup>, 
        <a target="_blank" href="https://yizhongzhang1989.github.io/">Yizhong&nbsp;Zhang</a><sup></sup>,
        <a target="_blank" href="https://yudeng.github.io/">Yu&nbsp;Deng</a><sup></sup>,
        <a target="_blank" href="https://www.microsoft.com/en-us/research/people/stevelin/">Steve&nbsp;Lin</a><sup></sup>,
        <a target="_blank" href="https://www.microsoft.com/en-us/research/people/bainguo/">Baining&nbsp;Guo</a><sup></sup>
      </span>
      <span>Microsoft Research Asia<br /><sup>*</sup>Equal Contributions&nbsp;&nbsp;<sup>‡</sup>Corresponding Author: jiaoyan@microsoft.com</span>
      <div class="flex flex-gap" style="margin-bottom:0.5em;">
        <a target="_blank" href="https://arxiv.org/abs/xxxx.xxxxx"><button>arXiv</button></a>
        <a target="_blank" href="https://arxiv.org/pdf/xxxx.xxxxx.pdf"><button>PDF</button></a>
      </div>
      <small><span><b>TL;DR</b>: Single portrait photo to realistic and expressive 3D head avatar, animatable with speech audios to create <i>3D free-viewpoint</i> talking face videos with <i>precise lip-audio sync</i>, <i>lifelike facial behavior</i>, and <i>natural head movements</i>, in <i>real time</i>.</span></small>
      <div class='responsive-image-container'>
        <img src='image/teaser.jpg' alt='' />
      </div>
    </div>
    <div id="abstract-flex" class="column-flex">
      <h2>Abstract</h2>
      <small>
        <p>
          We propose VASA-3D, an audio-driven, single-shot 3D head avatar generator. This research tackles two major challenges: capturing the subtle expression details present in real human faces, and reconstructing an intricate 3D head avatar from a single portrait image. To accurately model expression details, VASA-3D leverages the motion latent of <a target="_blank" href="https://www.microsoft.com/en-us/research/project/vasa-1/">VASA-1</a>, a method that yields exceptional realism and vividness in 2D talking heads. A critical element of our work is translating this motion latent to 3D, which is accomplished by devising a 3D head model that is conditioned on the motion latent. Customization of this model to a single image is achieved through an optimization framework that employs numerous video frames of the reference head synthesized from the input image. The optimization takes various training losses robust to artifacts and limited pose coverage in the generated training data. Our experiment shows that VASA-3D produces realistic 3D talking heads that cannot be achieved by prior art, and it supports the online generation of 512x512 free-viewpoint videos at up to 75 FPS, facilitating more immersive engagements with  lifelike 3D avatars.
        </p>
      </small>
    </div>
    <div id="sections" class="column-flex">
	<p style="color:#700000"><i>(Note: all portrait images on this page are virtual, non-existing identities generated by StyleGAN2 or DALL·E-3. We are exploring visual affective skill generation for virtual, interactive characters to support positive applications, NOT impersonating any person in the real world. This is only a research demonstration and we must ensure responsible usage of similar technologies. See the “Responsible AI considerations” section for more information.)</i></p>
	<h3>Real-time Demo</h3>
      <p>
       Our method generates 3D talking head frames of 512x512 size at <b>75fps</b> with a preceding latency of only 65ms, evaluated on a desktop PC with a single NVIDIA RTX 4090 GPU. Speed test is conducted with a naively implementation without optimization. 
      </p>  
	  <video controls playsInline src="video/vasa3d_demo.mp4" width="50%"></video>

  <h3>Expressive 3D dynamic heads</h3>
      <p>
        Our method transforms a single portrait image into a lifelike 3D talking head, synchronized with any speech audio input. Our model ensures multiview consistency and facilitates real-time audio-driven animation and free-view rendering, captures and conveys dynamic expression details with a degree of realism that markedly exceeds current state-of-the-art techniques.
      </p>
      <div class="video-slider">
        <video src="video/001.mp4"></video>
        <video src="video/019.mp4"></video>
        <video src="video/005.mp4"></video>
        <video src="video/007.mp4"></video>
        <video src="video/018.mp4"></video>
        <video src="video/009.mp4"></video>
        <video src="video/006.mp4"></video>
        <video src="video/004.mp4"></video>
      </div>
      
      <h3>Artistic Portraits</h3>
      <p>
        Our method can also effectively handle artistic images and produce convincing 3D talking heads.
      </p>
      <div class="video-slider one-row">
        <video src="video/012.mp4"></video>
        <video src="video/014.mp4"></video>
        <video src="video/015.mp4"></video>
        <video src="video/016.mp4"></video>
      </div>
      <h3>Controllablity</h3>
      <p>
        Inheriting the capabilities of VASA-1, our VASA-3D can take additional control signals besides an audio clip. Here we present the results with emotion offset control, where the generated 3D talking heads closely adhere to different emotion offsets and exhibite motive talking styles.
      </p>
        <video controls playsInline src="video/emotion.mp4" width="100%"></video>


      <br /><br />
      <h3>Risks and responsible AI considerations</h3>
      <p>Our research aims to support positive applications of virtual AI avatars and is not intended for creating misleading or deceptive content. However, like other related techniques, VASA-3D could potentially be misused in generating the likeness of a real person. Throughout the development of VASA-3D, responsible AI considerations were factored into all stages. To safeguard against such harm, we are training face forgery detection models that incorporate our models' outputs as part of the training data. Though VASA-3D produces visually realistic results, we have found that they are easily distinguishable from authentic videos by these models and improve the models’ generalizability.<br /><br />

        While recognizing the potential for misuse, it is important to acknowledge the substantial positive impact that our research technique could eventually have. We are currently examining potential benefits, such as its application in an AI coworker and AI tutor, which can enhance latent intelligence accessibility for knowledge workers and learners. These applications highlight the significance of this research and other related investigations. We are committed to developing AI responsibly, with the goal of advancing human well-being.
        </p>

      <h3 class="title">BibTeX</h3>
          <pre>
          <code>@inproceedings{vasa3d,
            title={VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image},
            author={Xu, Sicheng and Chen, Guojun and Yang, Jiaolong and Zhang, Yizhong and Deng, Yu and Lin, Steve and Guo, Baining},
            booktitle={Advances in Neural Information Processing Systems},
            year={2025}
          }  
      </code></pre>



      <div style="display: flex; flex-direction: row; gap: 8px;">
      <a href="https://go.microsoft.com/fwlink/?LinkId=521839">Privacy & Cookies</a>
      <span style="width: 1px; background-color: rgba(255, 255, 255, 0.7);"></span>
      <a href="https://go.microsoft.com/fwlink/?linkid=2259814">Consumer Health Privacy</a>
      <span style="width: 1px; background-color: rgba(255, 255, 255, 0.7);"></span>
      <a href="https://go.microsoft.com/fwlink/?LinkID=246338">Terms of Use</a>
      <span style="width: 1px; background-color: rgba(255, 255, 255, 0.7);"></span>
      <a href="https://go.microsoft.com/fwlink/?linkid=2196228">Trademarks</a>
      <span style="width: 1px; background-color: rgba(255, 255, 255, 0.7);"></span>
      <span>© 2025 Microsoft</span>
      </div>
    </div>
  </div>
  </div>
  
  <script src="index.js"></script>
</body>


</html>